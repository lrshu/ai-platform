# Implementation Plan: RAG Backend System

**Branch**: `001-rag-backend` | **Date**: 2025-11-22 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-rag-backend/spec.md`

## Summary

Build a standardized RAG (Retrieval-Augmented Generation) backend system with complete pipeline: Indexing → Pre-Retrieval → Retrieval → Post-Retrieval → Generation → Orchestration. The system will process PDF documents, create vector embeddings, perform hybrid search (vector + keyword + graph), rerank results, and generate natural language answers with citations using LangChain framework and Qwen models.

**Technical Approach**: Python-based backend using LangChain Core for RAG pipeline orchestration, Memgraph for graph storage and metadata, vector database for similarity search, Qwen models for embedding and generation, DashScope for reranking. CLI interface for indexing, search, and chat operations.

## Technical Context

**Language/Version**: Python 3.12+ (managed with uv package manager)
**Primary Dependencies**:
- LangChain Core (RAG pipeline orchestration)
- langchain-community (vector stores, document loaders)
- pymupdf4llm (PDF to markdown parsing)
- neo4j (Memgraph Python driver for graph operations)
- openai (Qwen API client via OpenAI-compatible interface)
- dashscope (Qwen embedding and rerank)

**Storage**:
- Memgraph (graph database via Neo4j protocol) for document metadata and relationships
- Chroma (embedded mode) for vector similarity search
- File system for original documents

**Testing**: pytest with pytest-asyncio for async operations
**Target Platform**: Linux/macOS server (Docker-compatible)
**Project Type**: Single project (backend service with CLI)

**Performance Goals**:
- Indexing: 10 pages/second
- Retrieval: <500ms for vector+keyword+graph hybrid search
- Generation: <3 seconds end-to-end
- Support 10 concurrent requests

**Constraints**:
- Query response time p95 <5 seconds
- Support documents up to 10MB
- Maintain 1,000 documents with 10,000+ chunks
- No memory leaks during long-running operations

**Scale/Scope**:
- 1,000 documents indexed
- 10,000+ chunks searchable
- 10 concurrent users
- Single-tenant deployment (MVP)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### I. Code Quality Standards
- ✅ **Type Safety**: Python 3.12+ with full type hints for all functions
- ✅ **Linting**: ruff for linting and formatting
- ✅ **Complexity**: Modular design with single-purpose functions
- ✅ **Documentation**: Docstrings for all public APIs and pipeline stages
- ⚠️ **Complexity Justification Required**: LangChain introduces abstraction layer

### II. Test-First Development
- ✅ **Contract Tests**: Required for CLI interface, API endpoints, and pipeline stages
- ✅ **Integration Tests**: Required for end-to-end RAG pipeline flows
- ✅ **Unit Tests**: Required for parsing, chunking, embedding, retrieval logic
- ✅ **Coverage**: Target 80% minimum, 90% for critical paths (retrieval, generation)

### III. User Experience Consistency
- ✅ **CLI Standards**: Consistent command structure (indexing, search, chat)
- ✅ **Error Messages**: Clear error handling with actionable messages
- ✅ **Progress Indicators**: For document indexing >2 seconds
- ✅ **Output Formats**: JSON for programmatic use, formatted text for human readability

### IV. Performance & Reliability Standards
- ✅ **Response Time**: <5s for query (p95), <3s for generation
- ✅ **Resource Efficiency**: Async I/O for external APIs, connection pooling for databases
- ✅ **Error Handling**: Retry logic for transient failures, fallback for model unavailability
- ✅ **Logging**: Structured JSON logging for all pipeline stages

**Gate Status**: ⚠️ **CONDITIONAL PASS** - Must justify LangChain complexity in Complexity Tracking

## Project Structure

### Documentation (this feature)

```text
specs/001-rag-backend/
├── plan.md              # This file
├── research.md          # Phase 0: Technology decisions and best practices
├── data-model.md        # Phase 1: Entity definitions and relationships
├── quickstart.md        # Phase 1: Setup and usage guide
├── contracts/           # Phase 1: API/CLI interface contracts
│   ├── cli-spec.md
│   └── pipeline-api.md
└── tasks.md             # Phase 2: Generated by /speckit.tasks
```

### Source Code (repository root)

```text
src/
├── rag/
│   ├── __init__.py
│   ├── indexing.py          # Document parsing, chunking, embedding, storage
│   ├── pre_retrieval.py     # Query expansion and preprocessing
│   ├── retrieval.py         # Hybrid search (vector + keyword + graph)
│   ├── post_retrieval.py    # Reranking and filtering
│   ├── generation.py        # LLM answer generation with citations
│   └── orchestration.py     # Pipeline coordination and configuration
├── storage/
│   ├── __init__.py
│   ├── vector_store.py      # Vector database operations
│   └── graph_store.py       # Memgraph operations
├── models/
│   ├── __init__.py
│   ├── document.py          # Document entity
│   └── query.py             # Query and response entities
├── cli/
│   ├── __init__.py
│   └── main.py              # CLI entry point (indexing, search, chat)
└── config/
    ├── __init__.py
    └── settings.py          # Configuration and environment variables

tests/
├── contract/
│   ├── test_cli_interface.py
│   └── test_pipeline_contracts.py
├── integration/
│   ├── test_indexing_flow.py
│   ├── test_retrieval_flow.py
│   └── test_end_to_end.py
└── unit/
    ├── test_parsing.py
    ├── test_chunking.py
    ├── test_embedding.py
    ├── test_retrieval.py
    └── test_generation.py

.env                         # Environment configuration (not in git)
pyproject.toml               # Project dependencies and metadata
README.md                    # Project overview and setup
```

**Structure Decision**: Single project structure chosen because this is a backend service with CLI interface. All RAG pipeline components are tightly coupled and should be in one codebase for maintainability. The modular structure separates concerns (indexing, retrieval, generation) while keeping related code together.

## Complexity Tracking

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| LangChain framework | Provides standardized RAG patterns, document loaders, text splitters, vector store abstractions, and LLM integrations. Reduces boilerplate for common RAG operations. | Building from scratch would require reimplementing document parsing, chunking strategies, vector store interfaces, LLM prompt templates, and retry logic - significant development and maintenance burden. LangChain is industry-standard for RAG systems. |
| Memgraph + Vector DB dual storage | Memgraph stores document relationships and metadata in graph format for complex queries. Vector DB provides fast similarity search. Hybrid approach enables graph-enhanced retrieval. | Single vector database cannot efficiently handle complex entity relationships and knowledge graph queries. Single graph database would be slower for high-dimensional vector similarity search. Dual storage is standard for advanced RAG systems. |
| Hybrid Search (Vector + Keyword + Graph) | Vector search finds semantic similarity, keyword search catches exact matches, graph search leverages relationships. Combining all three improves recall and relevance. | Vector-only search misses exact term matches and ignores document relationships. Keyword-only search misses semantic meaning. Graph-only search requires explicit relationships. Hybrid search is best practice for production RAG systems. |
